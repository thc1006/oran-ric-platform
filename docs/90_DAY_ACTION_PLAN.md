# O-RAN RIC Platform 90 å¤©è¡Œå‹•è¨ˆåŠƒ

**ä½œè€…**: è”¡ç§€å‰ (thc1006)
**é–‹å§‹æ—¥æœŸ**: 2025-11-18ï¼ˆé€±ä¸€ï¼‰
**çµæŸæ—¥æœŸ**: 2026-02-16ï¼ˆé€±æ—¥ï¼‰
**ç¸½å·¥æ™‚**: 214.5 å°æ™‚
**åœ˜éšŠè¦æ¨¡**: 2 FTE (Full-Time Engineers)

---

## ğŸ“‹ ç›®éŒ„

- [Phase 0: ç·Šæ€¥ä¿®å¾©](#phase-0-ç·Šæ€¥ä¿®å¾©-week-0)
- [Phase 1: å®‰å…¨å¼·åŒ–](#phase-1-å®‰å…¨å¼·åŒ–-week-1-4)
- [Phase 2: é«˜å¯ç”¨æ€§èˆ‡æ•ˆèƒ½](#phase-2-é«˜å¯ç”¨æ€§èˆ‡æ•ˆèƒ½-week-5-8)
- [Phase 3: æ¸¬è©¦èˆ‡ CI/CD](#phase-3-æ¸¬è©¦èˆ‡-cicd-week-9-12)
- [é™„éŒ„: é©—æ”¶æ¨™æº–](#é™„éŒ„é©—æ”¶æ¨™æº–)

---

## Phase 0: ç·Šæ€¥ä¿®å¾© (Week 0)

### ğŸ“… æ™‚ç¨‹ï¼š2025-11-18 ~ 2025-11-20 (3 å¤©)

### ğŸ¯ ç›®æ¨™
- æ¶ˆé™¤æ‰€æœ‰ Critical è³‡æ–™ä¸Ÿå¤±é¢¨éšª
- ä¿®å¾©æœ€åš´é‡çš„å®‰å…¨æ¼æ´
- å»ºç«‹åŸºæœ¬å‚™ä»½æ©Ÿåˆ¶

### ğŸ“Š æˆåŠŸæŒ‡æ¨™
- âœ… Redis è³‡æ–™æŒä¹…åŒ–å•Ÿç”¨
- âœ… InfluxDB ç£ç¢Ÿä½¿ç”¨é‡ < 10 Gi
- âœ… ç„¡æ˜æ–‡å¯†ç¢¼å­˜åœ¨æ–¼é…ç½®æª”æ¡ˆ
- âœ… æ¯æ—¥å‚™ä»½æˆåŠŸåŸ·è¡Œ

---

### ä»»å‹™ 1: å•Ÿç”¨ Redis AOF æŒä¹…åŒ– ğŸ”´

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 2 å°æ™‚
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å‚™ä»½ç•¶å‰é…ç½®
kubectl get configmap dbaas-config -n ricplt -o yaml > /tmp/dbaas-config-backup.yaml

# Step 2: ç·¨è¼¯ ConfigMap
kubectl edit configmap dbaas-config -n ricplt

# ä¿®æ”¹ä»¥ä¸‹åƒæ•¸:
#   appendonly: "yes"          # å•Ÿç”¨ AOF
#   appendfsync: "everysec"    # æ¯ç§’åŒæ­¥
#   save: "900 1 300 10 60 10000"  # RDB å¿«ç…§ç­–ç•¥

# Step 3: é‡å•Ÿ Redis Pod
kubectl rollout restart deployment/dbaas -n ricplt

# Step 4: é©—è­‰ AOF æª”æ¡ˆç”Ÿæˆ
kubectl exec -it dbaas-xxxxx -n ricplt -- ls -lh /data/
# æ‡‰è©²çœ‹åˆ° appendonly.aof æª”æ¡ˆ

# Step 5: é©—è­‰æŒä¹…åŒ–é…ç½®
kubectl exec -it dbaas-xxxxx -n ricplt -- redis-cli CONFIG GET appendonly
# æ‡‰å›å‚³ appendonly: yes
```

#### é©—æ”¶æ¨™æº–
- [ ] `appendonly.aof` æª”æ¡ˆå­˜åœ¨æ–¼ `/data/` ç›®éŒ„
- [ ] AOF æª”æ¡ˆå¤§å° > 0 bytes
- [ ] Redis INFO é¡¯ç¤º `aof_enabled:1`
- [ ] åŸ·è¡Œ `BGREWRITEAOF` æˆåŠŸ

#### æ½›åœ¨å•é¡Œ
- **AOF é‡å¯«é˜»å¡**: è§£æ±ºæ–¹æ¡ˆ - `auto-aof-rewrite-min-size 64mb`
- **ç£ç¢Ÿç©ºé–“ä¸è¶³**: ç¢ºèª PVC æœ‰è¶³å¤ ç©ºé–“ (è‡³å°‘ 5Gi å¯ç”¨)

---

### ä»»å‹™ 2: è¨­å®š InfluxDB Retention Policy ğŸ”´

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 1 å°æ™‚
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: é€²å…¥ InfluxDB Pod
kubectl exec -it influxdb-0 -n ricplt -- sh

# Step 2: æŸ¥çœ‹ç•¶å‰ bucket é…ç½®
influx bucket list

# Step 3: æ›´æ–° Retention Policy (90 å¤©)
influx bucket update \
  --id <bucket-id> \
  --retention 90d \
  --shard-group-duration 1d

# Step 4: é©—è­‰è¨­å®š
influx bucket list
# retention æ‡‰é¡¯ç¤º 2160h0m0s (90 å¤©)

# Step 5: å¼·åˆ¶åŸ·è¡ŒèˆŠè³‡æ–™æ¸…ç†
influx task create \
  --name cleanup-old-data \
  --every 1d \
  --flux '
    from(bucket: "ricplt")
      |> range(start: -91d, stop: -90d)
      |> filter(fn: (r) => true)
      |> drop()
  '
```

#### é©—æ”¶æ¨™æº–
- [ ] Retention Policy è¨­å®šç‚º 90 å¤©
- [ ] Shard group duration ç‚º 1 å¤©
- [ ] åŸ·è¡Œ `influx bucket list` é¡¯ç¤ºæ­£ç¢ºé…ç½®
- [ ] ç£ç¢Ÿä½¿ç”¨é‡é–‹å§‹ä¸‹é™

#### ç›£æ§
```bash
# æ¯æ—¥æª¢æŸ¥ç£ç¢Ÿä½¿ç”¨é‡
kubectl exec -it influxdb-0 -n ricplt -- du -sh /var/lib/influxdb2
```

---

### ä»»å‹™ 3: ç§»é™¤ Grafana æ˜æ–‡å¯†ç¢¼ ğŸ”´

**è² è²¬äºº**: Security Engineer
**å·¥æ™‚**: 2 å°æ™‚
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç”Ÿæˆå¼·å¯†ç¢¼
GRAFANA_PASSWORD=$(openssl rand -base64 32)
echo "New Grafana password: $GRAFANA_PASSWORD"
# âš ï¸ å¦¥å–„ä¿å­˜æ­¤å¯†ç¢¼

# Step 2: å‰µå»º Kubernetes Secret
kubectl create secret generic grafana-admin-secret \
  --from-literal=admin-user=admin \
  --from-literal=admin-password=$GRAFANA_PASSWORD \
  -n ricplt

# Step 3: æ›´æ–° Helm values
cat > /tmp/grafana-values-patch.yaml <<EOF
admin:
  existingSecret: grafana-admin-secret
  userKey: admin-user
  passwordKey: admin-password
EOF

# Step 4: å‡ç´š Grafana
helm upgrade oran-grafana ric/grafana \
  -n ricplt \
  -f config/grafana-values.yaml \
  -f /tmp/grafana-values-patch.yaml

# Step 5: å¾ Git ç§»é™¤æ˜æ–‡å¯†ç¢¼
cd /home/thc1006/oran-ric-platform
git checkout config/grafana-values.yaml
# ç·¨è¼¯æª”æ¡ˆç§»é™¤ adminPassword è¡Œ
git add config/grafana-values.yaml
git commit -m "security: Remove hardcoded Grafana password"
```

#### é©—æ”¶æ¨™æº–
- [ ] Grafana Pod æˆåŠŸé‡å•Ÿ
- [ ] å¯ç”¨æ–°å¯†ç¢¼ç™»å…¥ Grafana UI
- [ ] `config/grafana-values.yaml` ç„¡æ˜æ–‡å¯†ç¢¼
- [ ] Secret å­˜åœ¨: `kubectl get secret grafana-admin-secret -n ricplt`

---

### ä»»å‹™ 4: Redis å•Ÿç”¨å¯†ç¢¼èªè­‰ ğŸ”´

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 3 å°æ™‚
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç”Ÿæˆ Redis å¯†ç¢¼
REDIS_PASSWORD=$(openssl rand -base64 32)
echo "Redis password: $REDIS_PASSWORD"

# Step 2: å‰µå»º Secret
kubectl create secret generic redis-auth \
  --from-literal=password=$REDIS_PASSWORD \
  -n ricplt

# Step 3: æ›´æ–° Redis ConfigMap
kubectl edit configmap dbaas-config -n ricplt

# æ·»åŠ :
#   requirepass: "${REDIS_PASSWORD}"  # å¾ Secret è®€å–
#   protected-mode: "yes"
#   bind: "127.0.0.1"  # åƒ…ç›£è½ localhost

# Step 4: æ›´æ–° DBaaS Deployment æ›è¼‰ Secret
kubectl edit deployment dbaas -n ricplt

# æ·»åŠ ç’°å¢ƒè®Šæ•¸:
# env:
# - name: REDIS_PASSWORD
#   valueFrom:
#     secretKeyRef:
#       name: redis-auth
#       key: password

# Step 5: é‡å•Ÿ Redis
kubectl rollout restart deployment/dbaas -n ricplt

# Step 6: æ›´æ–°æ‰€æœ‰ xApp çš„ Redis é€£ç·šé…ç½®
# (KPIMON, Traffic Steering, QoE Predictor, RAN Control, FL)
```

#### xApp é…ç½®æ›´æ–°ç¯„ä¾‹

```yaml
# æ¯å€‹ xApp deployment.yaml
env:
- name: SDL_PASSWORD
  valueFrom:
    secretKeyRef:
      name: redis-auth
      key: password
```

#### é©—æ”¶æ¨™æº–
- [ ] Redis éœ€è¦å¯†ç¢¼æ‰èƒ½é€£ç·š
- [ ] æ‰€æœ‰ xApp Pods æˆåŠŸé€£ç·š Redis
- [ ] æ¸¬è©¦ç„¡å¯†ç¢¼é€£ç·šè¢«æ‹’çµ•: `redis-cli PING` å›å‚³ `NOAUTH`

---

### ä»»å‹™ 5: E2 Simulator æ·»åŠ  FL é…ç½® ğŸŸ 

**è² è²¬äºº**: Developer
**å·¥æ™‚**: 30 åˆ†é˜
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç·¨è¼¯ E2 Simulator ä»£ç¢¼
vim simulator/e2-simulator/src/e2_simulator.py

# åœ¨ Line 54 æ·»åŠ :
'federated-learning': {
    'host': 'federated-learning.ricxapp.svc.cluster.local',
    'port': 8110,
    'endpoint': '/e2/indication'
}

# Step 2: é‡å»º Docker æ˜ åƒ
cd simulator/e2-simulator
docker build -t localhost:5000/e2-simulator:1.0.1 .
docker push localhost:5000/e2-simulator:1.0.1

# Step 3: æ›´æ–° deployment.yaml
vim deploy/deployment.yaml
# ä¿®æ”¹ image tag: 1.0.0 â†’ 1.0.1

# Step 4: é‡æ–°éƒ¨ç½²
kubectl apply -f deploy/deployment.yaml -n ricxapp
```

#### é©—æ”¶æ¨™æº–
- [ ] E2 Simulator æ—¥èªŒé¡¯ç¤ºå‘ FL ç™¼é€æµé‡
- [ ] FL xApp æ¥æ”¶åˆ° E2 indications
- [ ] `kubectl logs -n ricxapp -l app=e2-simulator | grep federated`

---

### ä»»å‹™ 6: å»ºç«‹å‚™ä»½ CronJob ğŸŸ 

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 2 å°æ™‚
**å„ªå…ˆç´š**: P0

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å‰µå»ºå‚™ä»½è…³æœ¬ ConfigMap
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-scripts
  namespace: ricplt
data:
  backup-redis.sh: |
    #!/bin/bash
    DATE=\$(date +%Y%m%d-%H%M%S)
    kubectl exec -n ricplt dbaas-xxxxx -- redis-cli BGSAVE
    sleep 10
    kubectl cp ricplt/dbaas-xxxxx:/data/dump.rdb /backup/redis-\$DATE.rdb
    find /backup/redis-*.rdb -mtime +7 -delete

  backup-influxdb.sh: |
    #!/bin/bash
    DATE=\$(date +%Y%m%d-%H%M%S)
    kubectl exec -n ricplt influxdb-0 -- \
      influx backup /tmp/backup-\$DATE
    kubectl cp ricplt/influxdb-0:/tmp/backup-\$DATE /backup/influxdb-\$DATE
    find /backup/influxdb-* -mtime +7 -delete
EOF

# Step 2: å‰µå»º CronJob
cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: CronJob
metadata:
  name: backup-databases
  namespace: ricplt
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨ 2:00
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: backup
            image: bitnami/kubectl:latest
            command:
            - /bin/bash
            - -c
            - |
              /scripts/backup-redis.sh
              /scripts/backup-influxdb.sh
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-scripts
            configMap:
              name: backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
EOF

# Step 3: å‰µå»ºå‚™ä»½ PVC
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-pvc
  namespace: ricplt
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: local-path
EOF
```

#### é©—æ”¶æ¨™æº–
- [ ] CronJob å·²å‰µå»º: `kubectl get cronjob -n ricplt`
- [ ] PVC å·²ç¶å®š: `kubectl get pvc backup-pvc -n ricplt`
- [ ] æ‰‹å‹•è§¸ç™¼æ¸¬è©¦: `kubectl create job --from=cronjob/backup-databases test-backup -n ricplt`
- [ ] å‚™ä»½æª”æ¡ˆå­˜åœ¨æ–¼ `/backup` ç›®éŒ„

---

### Week 0 Checklist

- [ ] æ‰€æœ‰ 6 å€‹ä»»å‹™å®Œæˆ
- [ ] é©—æ”¶æ¨™æº–å…¨éƒ¨é€šé
- [ ] æ›´æ–°æ–‡æª”è¨˜éŒ„è®Šæ›´
- [ ] å‘åœ˜éšŠå±•ç¤ºæˆæœ
- [ ] æº–å‚™ Week 1 Sprint Planning

---

## Phase 1: å®‰å…¨å¼·åŒ– (Week 1-4)

### Sprint 1: å¯†ç¢¼èˆ‡å¯†é‘°ç®¡ç† (Week 1-2)

#### ğŸ“… æ™‚ç¨‹ï¼š2025-11-21 ~ 2025-12-04 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å¯¦æ–½ Sealed Secrets Operator
- è¼ªæ›¿æ‰€æœ‰æœå‹™å¯†ç¢¼
- æ¸…ç† Git æ­·å²ä¸­çš„æ•æ„Ÿè³‡è¨Š
- æ•´åˆæ˜ åƒæ¼æ´æƒæ

---

### ä»»å‹™ 7: å®‰è£ Sealed Secrets Operator

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 4 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: æ·»åŠ  Helm repo
helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets
helm repo update

# Step 2: å®‰è£ Sealed Secrets Controller
helm install sealed-secrets sealed-secrets/sealed-secrets \
  --namespace kube-system \
  --set-string fullnameOverride=sealed-secrets-controller

# Step 3: å®‰è£ kubeseal CLI
wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.24.0/kubeseal-0.24.0-linux-amd64.tar.gz
tar -xvzf kubeseal-0.24.0-linux-amd64.tar.gz
sudo mv kubeseal /usr/local/bin/
kubeseal --version

# Step 4: æ¸¬è©¦ Sealed Secrets
kubectl create secret generic test-secret \
  --from-literal=foo=bar \
  --dry-run=client \
  -o yaml | \
  kubeseal -o yaml > test-sealed-secret.yaml

kubectl apply -f test-sealed-secret.yaml
kubectl get secret test-secret  # æ‡‰è©²å­˜åœ¨
```

#### é©—æ”¶æ¨™æº–
- [ ] Sealed Secrets Controller Pod é‹è¡Œä¸­
- [ ] kubeseal CLI å¯ç”¨
- [ ] æ¸¬è©¦ SealedSecret æˆåŠŸè§£å¯†ç‚º Secret

---

### ä»»å‹™ 8: è¼ªæ›¿æ‰€æœ‰æœå‹™å¯†ç¢¼

**è² è²¬äºº**: Security Engineer
**å·¥æ™‚**: 4 å°æ™‚
**å„ªå…ˆç´š**: P1

#### æœå‹™æ¸…å–®

| æœå‹™ | ç•¶å‰å¯†ç¢¼ | æ–°å¯†ç¢¼ä½ç½® |
|------|---------|-----------|
| Grafana | oran-ric-admin | grafana-admin-secret (å·²å®Œæˆ) |
| VES Manager | sample1 | vesmgr-auth-secret |
| AppManager Helm Repo | helm/helm | appmgr-helm-secret |
| InfluxDB | admin/admin | influxdb-auth-secret |
| Redis | (ç„¡) | redis-auth (å·²å®Œæˆ) |

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# ä½¿ç”¨è‡ªå‹•åŒ–è…³æœ¬
cd /home/thc1006/oran-ric-platform
bash scripts/security/rotate-secrets.sh

# è…³æœ¬æœƒè‡ªå‹•:
# 1. ç”Ÿæˆæ–°å¯†ç¢¼
# 2. å‰µå»º Sealed Secrets
# 3. æ›´æ–°æ‰€æœ‰ç›¸é—œ Deployments
# 4. æ»¾å‹•é‡å•Ÿå—å½±éŸ¿çš„ Pods
# 5. é©—è­‰æœå‹™æ­£å¸¸é‹è¡Œ
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰€æœ‰æœå‹™ä½¿ç”¨æ–°å¯†ç¢¼
- [ ] æ²’æœ‰ Pod è™•æ–¼ CrashLoopBackOff
- [ ] æ–°å¯†ç¢¼è¨˜éŒ„åœ¨å¯†ç¢¼ç®¡ç†å™¨ï¼ˆ1Password/Vaultï¼‰
- [ ] èˆŠå¯†ç¢¼å·²å¤±æ•ˆ

---

### ä»»å‹™ 9: Git æ­·å²æ¸…ç†

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 2 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# âš ï¸ è­¦å‘Š: æ­¤æ“ä½œæœƒæ”¹å¯« Git æ­·å²ï¼Œéœ€åœ˜éšŠå”èª¿

# Step 1: å‚™ä»½å€‰åº«
cd /home/thc1006/oran-ric-platform
git clone --mirror . ../oran-ric-platform-backup.git

# Step 2: å®‰è£ BFG Repo-Cleaner
wget https://repo1.maven.org/maven2/com/madgag/bfg/1.14.0/bfg-1.14.0.jar
alias bfg='java -jar bfg-1.14.0.jar'

# Step 3: åˆªé™¤æ•æ„Ÿæª”æ¡ˆ
bfg --delete-files grafana-values.yaml
bfg --delete-files '*secret*.yaml'
bfg --replace-text passwords.txt  # åŒ…å«è¦ç§»é™¤çš„å¯†ç¢¼åˆ—è¡¨

# Step 4: æ¸…ç† reflog ä¸¦ GC
git reflog expire --expire=now --all
git gc --prune=now --aggressive

# Step 5: å¼·åˆ¶æ¨é€ (éœ€åœ˜éšŠé€šçŸ¥)
git push --force
```

#### passwords.txt ç¯„ä¾‹

```
oran-ric-admin==>***REMOVED***
sample1==>***REMOVED***
helm==>***REMOVED***
```

#### é©—æ”¶æ¨™æº–
- [ ] Git æ­·å²ä¸­ç„¡æ˜æ–‡å¯†ç¢¼
- [ ] ä½¿ç”¨ `git log --all -- config/grafana-values.yaml` ç„¡çµæœ
- [ ] åœ˜éšŠæˆå“¡é‡æ–° clone å€‰åº«

---

### ä»»å‹™ 10: æ•´åˆ Trivy æ˜ åƒæƒæ

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 6 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å®‰è£ Trivy
wget https://github.com/aquasecurity/trivy/releases/download/v0.47.0/trivy_0.47.0_Linux-64bit.tar.gz
tar -xzf trivy_0.47.0_Linux-64bit.tar.gz
sudo mv trivy /usr/local/bin/

# Step 2: æƒæç•¶å‰æ‰€æœ‰æ˜ åƒ
trivy image localhost:5000/xapp-kpimon:1.0.1
trivy image localhost:5000/xapp-traffic-steering:1.0.2
trivy image localhost:5000/xapp-qoe-predictor:1.0.1
trivy image localhost:5000/xapp-ran-control:1.0.1
trivy image localhost:5000/xapp-federated-learning:1.0.0
trivy image localhost:5000/e2-simulator:1.0.1

# Step 3: ç”Ÿæˆå ±å‘Š
trivy image --format json --output trivy-report.json \
  localhost:5000/xapp-kpimon:1.0.1

# Step 4: å‰µå»º GitHub Actions workflow
cat > .github/workflows/security-scan.yml <<EOF
name: Security Scan

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  trivy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: 'localhost:5000/xapp-kpimon:latest'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'
        exit-code: '1'  # ç™¼ç¾ Critical/High æ¼æ´æ™‚å¤±æ•—

    - name: Upload Trivy results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'
EOF

git add .github/workflows/security-scan.yml
git commit -m "ci: Add Trivy security scanning"
git push
```

#### é©—æ”¶æ¨™æº–
- [ ] Trivy æˆåŠŸæƒææ‰€æœ‰æ˜ åƒ
- [ ] GitHub Actions workflow é‹è¡ŒæˆåŠŸ
- [ ] Security tab é¡¯ç¤ºæƒæçµæœ
- [ ] æ‰€æœ‰ Critical æ¼æ´å·²ä¿®å¾©æˆ–è¨˜éŒ„

---

### ä»»å‹™ 11: å¯¦æ–½ Pod Security Standards

**è² è²¬äºº**: Security Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç‚º ricxapp namespace å•Ÿç”¨ PSS
kubectl label namespace ricxapp \
  pod-security.kubernetes.io/enforce=restricted \
  pod-security.kubernetes.io/audit=restricted \
  pod-security.kubernetes.io/warn=restricted

# Step 2: æ›´æ–°æ‰€æœ‰ xApp Deployments
# (traffic-steering, kpimon, ran-control)

cat > /tmp/security-context-patch.yaml <<EOF
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      containers:
      - name: xapp
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
        volumeMounts:
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: tmp
        emptyDir: {}
EOF

# Step 3: æ‡‰ç”¨ patch (æ¯å€‹ xApp)
kubectl patch deployment traffic-steering -n ricxapp --patch-file /tmp/security-context-patch.yaml
kubectl patch deployment kpimon -n ricxapp --patch-file /tmp/security-context-patch.yaml
kubectl patch deployment ran-control -n ricxapp --patch-file /tmp/security-context-patch.yaml

# Step 4: é©—è­‰ Pods é‡å•ŸæˆåŠŸ
kubectl get pods -n ricxapp -w
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰€æœ‰ xApp Pods ä»¥é root ç”¨æˆ¶é‹è¡Œ
- [ ] `kubectl get pod <pod-name> -n ricxapp -o jsonpath='{.spec.securityContext.runAsNonRoot}'` å›å‚³ `true`
- [ ] ç„¡ PSS é•è¦è­¦å‘Š

---

### Sprint 1 Review & Retrospective

**æ™‚é–“**: 2025-12-04 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] æ‰€æœ‰ Critical å¯†ç¢¼å·²è¼ªæ›¿
- [ ] Sealed Secrets å¯æ­£å¸¸ä½¿ç”¨
- [ ] Trivy æƒææ•´åˆåˆ° CI/CD
- [ ] Git æ­·å²ä¸­ç„¡æ•æ„Ÿè³‡è¨Š
- [ ] Pod Security Standards å¯¦æ–½

**å›é¡§å•é¡Œ**:
1. é‡åˆ°çš„æœ€å¤§æŒ‘æˆ°ï¼Ÿ
2. å“ªäº›ä»»å‹™æ¯”é ä¼°æ™‚é–“é•·ï¼Ÿ
3. ä¸‹å€‹ Sprint éœ€è¦æ”¹é€²çš„åœ°æ–¹ï¼Ÿ

---

### Sprint 2: ç¶²è·¯èˆ‡å­˜å–æ§åˆ¶ (Week 3-4)

#### ğŸ“… æ™‚ç¨‹ï¼š2025-12-05 ~ 2025-12-18 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å¯¦æ–½ Network Policy (Zero Trust)
- ç‚ºæ‰€æœ‰ xApps å»ºç«‹å°ˆå±¬ ServiceAccount
- RBAC æœ€å°æ¬Šé™å¯©æŸ¥
- å•Ÿç”¨ Service Mesh mTLS

---

### ä»»å‹™ 12: å¯¦æ–½ Network Policy

**è² è²¬äºº**: Network Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å¯¦æ–½ default-deny policy
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-deny-all
  namespace: ricxapp
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
EOF

# Step 2: ç‚ºæ¯å€‹ xApp å‰µå»º allow policy
# ç¯„ä¾‹: KPIMON
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: kpimon-allow
  namespace: ricxapp
spec:
  podSelector:
    matchLabels:
      app: kpimon
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: e2-simulator
    - namespaceSelector:
        matchLabels:
          name: ricplt
      podSelector:
        matchLabels:
          app: prometheus
    ports:
    - protocol: TCP
      port: 8080  # Metrics
    - protocol: TCP
      port: 8081  # API
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: ricplt
      podSelector:
        matchLabels:
          app: dbaas  # Redis SDL
    ports:
    - protocol: TCP
      port: 6379
  - to:
    - namespaceSelector:
        matchLabels:
          name: ricplt
      podSelector:
        matchLabels:
          app: influxdb
    ports:
    - protocol: TCP
      port: 8086
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
      podSelector:
        matchLabels:
          k8s-app: kube-dns
    ports:
    - protocol: UDP
      port: 53
EOF

# ç‚ºå…¶ä»– xApps é‡è¤‡ç›¸åŒæµç¨‹
```

#### é©—æ”¶æ¨™æº–
- [ ] default-deny policy å·²å¥—ç”¨
- [ ] æ¯å€‹ xApp æœ‰å°ˆå±¬çš„ allow policy
- [ ] xApps å¯æ­£å¸¸é€šè¨Šï¼ˆE2 Simulator â†’ xApps â†’ Redis â†’ InfluxDBï¼‰
- [ ] xApps ä¹‹é–“ç„¡æ³•ç›´æ¥é€šè¨Šï¼ˆé™¤éæ˜ç¢ºå…è¨±ï¼‰

---

### ä»»å‹™ 13: å»ºç«‹å°ˆå±¬ ServiceAccount

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 6 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç‚ºæ¯å€‹ xApp å‰µå»º ServiceAccount
cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kpimon-sa
  namespace: ricxapp
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traffic-steering-sa
  namespace: ricxapp
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ran-control-sa
  namespace: ricxapp
EOF

# Step 2: å‰µå»ºæœ€å°æ¬Šé™ Role
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: xapp-basic-role
  namespace: ricxapp
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
  resourceNames: ["redis-auth"]  # åƒ…å…è¨±è®€å– Redis å¯†ç¢¼
EOF

# Step 3: ç¶å®š Role åˆ° ServiceAccount
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: kpimon-binding
  namespace: ricxapp
subjects:
- kind: ServiceAccount
  name: kpimon-sa
roleRef:
  kind: Role
  name: xapp-basic-role
  apiGroup: rbac.authorization.k8s.io
EOF

# Step 4: æ›´æ–° Deployments ä½¿ç”¨æ–°çš„ ServiceAccount
kubectl patch deployment kpimon -n ricxapp -p '{"spec":{"template":{"spec":{"serviceAccountName":"kpimon-sa"}}}}'
```

#### é©—æ”¶æ¨™æº–
- [ ] æ¯å€‹ xApp æœ‰å°ˆå±¬ ServiceAccount
- [ ] ServiceAccount ç¶å®šåˆ°æœ€å°æ¬Šé™ Role
- [ ] xApps å¯æ­£å¸¸é‹è¡Œ
- [ ] ç„¡æ³•åŸ·è¡Œæœªæˆæ¬Šæ“ä½œï¼ˆæ¸¬è©¦: `kubectl auth can-i --as=system:serviceaccount:ricxapp:kpimon-sa delete pods -n ricxapp`ï¼‰

---

### ä»»å‹™ 14: RBAC æœ€å°æ¬Šé™å¯©æŸ¥

**è² è²¬äºº**: Security Engineer
**å·¥æ™‚**: 6 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å¯©æŸ¥æ‰€æœ‰ ClusterRoles
kubectl get clusterroles -o custom-columns=NAME:.metadata.name,AGE:.metadata.creationTimestamp | grep oran

# Step 2: æª¢æŸ¥ Prometheus ClusterRole æ¬Šé™
kubectl get clusterrole prometheus-server -o yaml

# Step 3: ç¸®æ¸›æ¬Šé™ï¼ˆç§»é™¤ä¸å¿…è¦çš„ resourcesï¼‰
kubectl edit clusterrole prometheus-server

# ç§»é™¤:
# - apiGroups: ["apps"]
#   resources: ["deployments"]
#
# ä¿ç•™:
# - apiGroups: [""]
#   resources: ["nodes", "services", "endpoints", "pods"]
#   verbs: ["get", "list", "watch"]

# Step 4: å¯©æŸ¥æ‰€æœ‰ RoleBindings
kubectl get rolebindings -n ricxapp -o yaml > /tmp/ricxapp-rolebindings.yaml

# Step 5: ç”Ÿæˆ RBAC å¯©è¨ˆå ±å‘Š
kubectl rbac-audit -n ricxapp > /tmp/rbac-audit-report.txt
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰€æœ‰ ClusterRoles éµå¾ªæœ€å°æ¬Šé™åŸå‰‡
- [ ] æ²’æœ‰ä¸å¿…è¦çš„ `*` æ¬Šé™
- [ ] RBAC å¯©è¨ˆå ±å‘Šç„¡é«˜å±ç™¼ç¾
- [ ] æ–‡æª”è¨˜éŒ„æ‰€æœ‰æ¬Šé™è®Šæ›´

---

### ä»»å‹™ 15: å•Ÿç”¨ Service Mesh mTLS

**è² è²¬äºº**: Platform Engineer
**å·¥æ™‚**: 12 å°æ™‚
**å„ªå…ˆç´š**: P1

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å®‰è£ Linkerd CLI
curl --proto '=https' --tlsv1.2 -sSfL https://run.linkerd.io/install | sh
export PATH=$PATH:$HOME/.linkerd2/bin

# Step 2: æª¢æŸ¥é›†ç¾¤ç›¸å®¹æ€§
linkerd check --pre

# Step 3: å®‰è£ Linkerd Control Plane
linkerd install --crds | kubectl apply -f -
linkerd install | kubectl apply -f -

# Step 4: é©—è­‰å®‰è£
linkerd check

# Step 5: ç‚º ricxapp namespace å•Ÿç”¨ auto-injection
kubectl annotate namespace ricxapp linkerd.io/inject=enabled

# Step 6: é‡å•Ÿæ‰€æœ‰ xApp Pods ä»¥æ³¨å…¥ sidecar
kubectl rollout restart deployment -n ricxapp

# Step 7: é©—è­‰ mTLS
linkerd viz stat deploy -n ricxapp
# MESHED æ¬„ä½æ‡‰é¡¯ç¤º 1/1

# Step 8: æª¢æŸ¥ mTLS ç‹€æ…‹
linkerd viz tap deploy/kpimon -n ricxapp
# æ‡‰çœ‹åˆ° "tls=true"
```

#### é©—æ”¶æ¨™æº–
- [ ] Linkerd Control Plane é‹è¡Œæ­£å¸¸
- [ ] æ‰€æœ‰ xApp Pods å·²æ³¨å…¥ Linkerd sidecar
- [ ] xApps ä¹‹é–“çš„é€šè¨Šä½¿ç”¨ mTLS
- [ ] Linkerd dashboard å¯è¦–åŒ–æµé‡æ‹“æ’²

---

### Sprint 2 Review & Retrospective

**æ™‚é–“**: 2025-12-18 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] Zero Trust ç¶²è·¯æ¨¡å‹å·²å¯¦æ–½
- [ ] æ‰€æœ‰ xApps ä½¿ç”¨å°ˆå±¬ ServiceAccount
- [ ] RBAC æ¬Šé™å·²æ”¶ç·Š
- [ ] Service Mesh mTLS å•Ÿç”¨

**é‡Œç¨‹ç¢‘**:
ğŸ‰ **Phase 1 å®Œæˆï¼å®‰å…¨æˆç†Ÿåº¦ 5/10 â†’ 7/10**

---

## Phase 2: é«˜å¯ç”¨æ€§èˆ‡æ•ˆèƒ½ (Week 5-8)

### Sprint 3: è³‡æ–™å±¤é«˜å¯ç”¨æ€§ (Week 5-6)

#### ğŸ“… æ™‚ç¨‹ï¼š2025-12-19 ~ 2026-01-01 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å‡ç´š Redis è‡³ Sentinel HA
- é…ç½® InfluxDB Clustering
- å¯¦æ–½ PostgreSQL HA

---

### ä»»å‹™ 16: å‡ç´š Redis è‡³ Sentinel

**è² è²¬äºº**: Database Engineer
**å·¥æ™‚**: 16 å°æ™‚
**å„ªå…ˆç´š**: P2

#### æ¶æ§‹è¨­è¨ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Linkerd Service Mesh          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Redis M   â”‚â—„â”€â”€â”¤ Redis S1  â”‚    â”‚
â”‚  â”‚ (Master)  â”‚   â”‚ (Slave)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚        â”‚                           â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚               â–¼                    â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚ Redis S2  â”‚              â”‚
â”‚         â”‚ (Slave)   â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚Sentinel â”‚ â”‚Sentinel â”‚ â”‚Sent..â”‚â”‚
â”‚  â”‚   1     â”‚ â”‚   2     â”‚ â”‚  3   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å‚™ä»½ç•¶å‰ Redis è³‡æ–™
kubectl exec -it dbaas-xxxxx -n ricplt -- redis-cli BGSAVE
kubectl cp ricplt/dbaas-xxxxx:/data/dump.rdb /backup/redis-pre-ha.rdb

# Step 2: éƒ¨ç½² Redis HA Helm Chart
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install redis-ha bitnami/redis \
  --namespace ricplt \
  --set architecture=replication \
  --set sentinel.enabled=true \
  --set master.persistence.enabled=true \
  --set master.persistence.size=20Gi \
  --set replica.replicaCount=2 \
  --set replica.persistence.enabled=true \
  --set replica.persistence.size=20Gi \
  --set sentinel.quorum=2 \
  --set master.resources.requests.memory=512Mi \
  --set master.resources.requests.cpu=250m \
  --set auth.enabled=true \
  --set auth.password="${REDIS_PASSWORD}"

# Step 3: ç­‰å¾…æ‰€æœ‰ Pods å°±ç·’
kubectl wait --for=condition=ready pod \
  -l app.kubernetes.io/name=redis \
  -n ricplt \
  --timeout=300s

# Step 4: é©—è­‰ Sentinel é…ç½®
kubectl exec -it redis-ha-master-0 -n ricplt -- redis-cli -a $REDIS_PASSWORD INFO replication
# role:master
# connected_slaves:2

# Step 5: æ¸¬è©¦æ•…éšœåˆ‡æ›
kubectl delete pod redis-ha-master-0 -n ricplt
# Sentinel æ‡‰è‡ªå‹•é¸èˆ‰æ–° Master
sleep 30
kubectl exec -it redis-ha-master-0 -n ricplt -- redis-cli -a $REDIS_PASSWORD ROLE
# æ‡‰é¡¯ç¤º master æˆ– slave

# Step 6: æ›´æ–° xApps é€£ç·šè‡³ Sentinel
# ä¿®æ”¹ xApps ConfigMap:
# REDIS_MASTER_SERVICE_HOST=redis-ha.ricplt.svc.cluster.local
# REDIS_SENTINEL_SERVICE_HOST=redis-ha.ricplt.svc.cluster.local
# REDIS_SENTINEL_PORT=26379

# Step 7: æ»¾å‹•é‡å•Ÿ xApps
kubectl rollout restart deployment -n ricxapp

# Step 8: é·ç§»è³‡æ–™ (å¦‚æœéœ€è¦)
# ä½¿ç”¨ redis-cli --rdb å¾èˆŠ Redis åŒæ­¥åˆ°æ–° Redis
```

#### é©—æ”¶æ¨™æº–
- [ ] Redis Master + 2 Replicas é‹è¡Œä¸­
- [ ] 3 å€‹ Sentinel å¯¦ä¾‹é‹è¡Œä¸­
- [ ] æ‰‹å‹•åˆªé™¤ Master Pod å¾Œè‡ªå‹•æ•…éšœåˆ‡æ›
- [ ] æ‰€æœ‰ xApps æˆåŠŸé€£ç·šæ–° Redis
- [ ] RTO < 30 ç§’, RPO < 1 ç§’

---

### ä»»å‹™ 17: é…ç½® InfluxDB Clustering

**è² è²¬äºº**: Database Engineer
**å·¥æ™‚**: 12 å°æ™‚
**å„ªå…ˆç´š**: P2

**æ³¨æ„**: InfluxDB 2.x OSS ç‰ˆæœ¬ä¸æ”¯æ´ clusteringã€‚éœ€è¦è€ƒæ…®ä»¥ä¸‹æ–¹æ¡ˆï¼š

#### æ–¹æ¡ˆé¸æ“‡

**æ–¹æ¡ˆ A: å‡ç´šè‡³ InfluxDB Enterpriseï¼ˆæ¨è–¦ï¼‰**
- æˆæœ¬: $$$
- å„ªé»: åŸç”Ÿ clusteringã€è‡ªå‹• sharding
- ç¼ºé»: å•†æ¥­æˆæ¬Š

**æ–¹æ¡ˆ B: ä½¿ç”¨ InfluxDB Relay + HAProxy**
- æˆæœ¬: $
- å„ªé»: é–‹æºæ–¹æ¡ˆ
- ç¼ºé»: é›™å¯«å¯èƒ½è³‡æ–™ä¸ä¸€è‡´

**æ–¹æ¡ˆ C: ä¿æŒå–®ç¯€é» + å¼·åŒ–å‚™ä»½**
- æˆæœ¬: ä½
- å„ªé»: ç°¡å–®
- ç¼ºé»: ä»æœ‰å–®é»æ•…éšœ

#### åŸ·è¡Œæ­¥é©Ÿï¼ˆæ–¹æ¡ˆ Bï¼‰

```bash
# Step 1: éƒ¨ç½²ç¬¬äºŒå€‹ InfluxDB å¯¦ä¾‹
helm install influxdb-2 influxdata/influxdb2 \
  --namespace ricplt \
  --set persistence.enabled=true \
  --set persistence.size=100Gi \
  --set resources.requests.memory=2Gi

# Step 2: éƒ¨ç½² InfluxDB Relay
cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: influxdb-relay
  namespace: ricplt
spec:
  replicas: 2
  selector:
    matchLabels:
      app: influxdb-relay
  template:
    metadata:
      labels:
        app: influxdb-relay
    spec:
      containers:
      - name: relay
        image: influxdata/influxdb-relay:latest
        ports:
        - containerPort: 9096
        volumeMounts:
        - name: config
          mountPath: /etc/influxdb-relay
      volumes:
      - name: config
        configMap:
          name: influxdb-relay-config
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: influxdb-relay-config
  namespace: ricplt
data:
  relay.toml: |
    [[http]]
    name = "ric-relay"
    bind-addr = "0.0.0.0:9096"
    output = [
      { name="influxdb1", location="http://influxdb-0.ricplt.svc:8086/write" },
      { name="influxdb2", location="http://influxdb-2-0.ricplt.svc:8086/write" }
    ]
EOF

# Step 3: æ›´æ–° xApps é€£ç·šè‡³ Relay
# INFLUXDB_URL=http://influxdb-relay.ricplt.svc:9096
```

#### é©—æ”¶æ¨™æº–
- [ ] å…©å€‹ InfluxDB å¯¦ä¾‹é‹è¡Œä¸­
- [ ] InfluxDB Relay é›™å¯«æˆåŠŸ
- [ ] æ‰‹å‹•åˆªé™¤ä¸€å€‹ InfluxDB å¾Œå¯«å…¥ä»æˆåŠŸ
- [ ] è³‡æ–™åŒæ­¥é©—è­‰ï¼ˆæŸ¥è©¢å…©å€‹å¯¦ä¾‹è³‡æ–™ä¸€è‡´ï¼‰

---

### ä»»å‹™ 18: å¯¦æ–½ PostgreSQL HA

**è² è²¬äºº**: Database Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P2

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: éƒ¨ç½² PostgreSQL HA (ä½¿ç”¨ Patroni)
helm repo add bitnami https://charts.bitnami.com/bitnami
helm install postgresql-ha bitnami/postgresql-ha \
  --namespace ricplt \
  --set postgresql.replicaCount=3 \
  --set postgresql.persistence.enabled=true \
  --set postgresql.persistence.size=20Gi \
  --set postgresql.auth.password="${POSTGRES_PASSWORD}"

# Step 2: é©—è­‰ Patroni é›†ç¾¤
kubectl exec -it postgresql-ha-postgresql-0 -n ricplt -- patronictl list
# æ‡‰é¡¯ç¤º Leader + 2 Replicas

# Step 3: é·ç§» Kong è³‡æ–™è‡³æ–° PostgreSQL
# (Kong æ˜¯å”¯ä¸€ä½¿ç”¨ PostgreSQL çš„çµ„ä»¶)

# Backup èˆŠè³‡æ–™
kubectl exec -it kong-postgresql-0 -n ricplt -- \
  pg_dump -U kong kong > /tmp/kong-backup.sql

# Restore åˆ°æ–° PostgreSQL
kubectl exec -it postgresql-ha-postgresql-0 -n ricplt -- \
  psql -U postgres -d kong -f /tmp/kong-backup.sql

# Step 4: æ›´æ–° Kong é€£ç·š
helm upgrade kong kong/kong \
  --namespace ricplt \
  --set postgresql.enabled=false \
  --set env.database=postgres \
  --set env.pg_host=postgresql-ha-postgresql.ricplt.svc \
  --set env.pg_port=5432 \
  --set env.pg_user=postgres \
  --set env.pg_password="${POSTGRES_PASSWORD}"

# Step 5: æ¸¬è©¦æ•…éšœåˆ‡æ›
kubectl delete pod postgresql-ha-postgresql-0 -n ricplt
# Patroni æ‡‰è‡ªå‹•é¸èˆ‰æ–° Leader
```

#### é©—æ”¶æ¨™æº–
- [ ] 3 ç¯€é» PostgreSQL é›†ç¾¤é‹è¡Œä¸­
- [ ] Patroni è‡ªå‹•æ•…éšœåˆ‡æ›æˆåŠŸ
- [ ] Kong æˆåŠŸé€£ç·šæ–° PostgreSQL
- [ ] è³‡æ–™å®Œæ•´æ€§é©—è­‰

---

### Sprint 3 Review

**æ™‚é–“**: 2026-01-01 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] Redis Sentinel HA é‹è¡Œä¸­
- [ ] InfluxDB é›™å¯«æ©Ÿåˆ¶é‹è¡Œä¸­
- [ ] PostgreSQL HA é‹è¡Œä¸­
- [ ] RTO < 5 åˆ†é˜, RPO < 1 åˆ†é˜

---

### Sprint 4: æ•ˆèƒ½èª¿æ ¡èˆ‡æ“´å±• (Week 7-8)

#### ğŸ“… æ™‚ç¨‹ï¼š2026-01-02 ~ 2026-01-15 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å„ªåŒ–è³‡æºé…ç½®
- å¯¦æ–½ HPA
- éƒ¨ç½² Jaeger åˆ†æ•£å¼è¿½è¹¤
- E2 indication batching å„ªåŒ–

---

### ä»»å‹™ 19: å„ªåŒ–è³‡æºé…ç½®

**è² è²¬äºº**: Performance Engineer
**å·¥æ™‚**: 4 å°æ™‚
**å„ªå…ˆç´š**: P2

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: æ‡‰ç”¨å„ªåŒ–é…ç½®
cp config/optimized-values.yaml /tmp/optimized-values.yaml

# Step 2: é€ä¸€å‡ç´šçµ„ä»¶
# Prometheus
helm upgrade r4-infrastructure-prometheus prometheus-community/prometheus \
  -n ricplt \
  -f /tmp/optimized-values.yaml

# Grafana
helm upgrade oran-grafana grafana/grafana \
  -n ricplt \
  -f /tmp/optimized-values.yaml

# æ‰€æœ‰ xApps
for xapp in kpimon traffic-steering qoe-predictor ran-control federated-learning; do
  kubectl set resources deployment/$xapp -n ricxapp \
    --requests=cpu=50m,memory=128Mi \
    --limits=cpu=200m,memory=512Mi
done

# Step 3: ç›£æ§è³‡æºä½¿ç”¨ç‡ï¼ˆ7 å¤©ï¼‰
kubectl top pods -n ricplt
kubectl top pods -n ricxapp
```

#### é©—æ”¶æ¨™æº–
- [ ] CPU ä½¿ç”¨ç‡ 30-70%
- [ ] Memory ä½¿ç”¨ç‡ 40-80%
- [ ] ç„¡ CPU throttling äº‹ä»¶
- [ ] ç„¡ OOMKilled Pods

---

### ä»»å‹™ 20: å¯¦æ–½ HPA

**è² è²¬äºº**: Platform Engineer
**å·¥æ™‚**: 12 å°æ™‚
**å„ªå…ˆç´š**: P2

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å®‰è£ Metrics Server (å¦‚æœå°šæœªå®‰è£)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Step 2: ç‚º E2Term å‰µå»º HPA
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: e2term-hpa
  namespace: ricplt
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: e2term
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
      - type: Pods
        value: 2
        periodSeconds: 30
      selectPolicy: Max
EOF

# Step 3: ç‚º KPIMON å‰µå»º HPA
cat <<EOF | kubectl apply -f -
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: kpimon-hpa
  namespace: ricxapp
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: kpimon
  minReplicas: 1
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: kpimon_messages_received_total
      target:
        type: AverageValue
        averageValue: "1000"  # æ¯å€‹ Pod è™•ç† 1000 msg/s
EOF

# Step 4: è² è¼‰æ¸¬è©¦é©—è­‰ HPA
# å¢åŠ  E2 Simulator æµé‡
kubectl scale deployment e2-simulator -n ricxapp --replicas=5
# è§€å¯Ÿ E2Term å’Œ KPIMON è‡ªå‹•æ“´å±•
watch kubectl get hpa -n ricplt
watch kubectl get hpa -n ricxapp
```

#### é©—æ”¶æ¨™æº–
- [ ] HPA æˆåŠŸå‰µå»º
- [ ] è² è¼‰å¢åŠ æ™‚è‡ªå‹•æ“´å±•
- [ ] è² è¼‰é™ä½æ™‚è‡ªå‹•ç¸®æ¸›
- [ ] æ“´å±•å»¶é² < 2 åˆ†é˜

---

### ä»»å‹™ 21: éƒ¨ç½² Jaeger åˆ†æ•£å¼è¿½è¹¤

**è² è²¬äºº**: Observability Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P2

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å®‰è£ Jaeger Operator
kubectl create namespace observability
kubectl apply -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.50.0/jaeger-operator.yaml -n observability

# Step 2: éƒ¨ç½² Jaeger å¯¦ä¾‹
cat <<EOF | kubectl apply -f -
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch:9200
  ingress:
    enabled: true
  query:
    serviceType: LoadBalancer
EOF

# Step 3: ç‚º xApps å•Ÿç”¨ tracing
# ä¿®æ”¹ xApp ä»£ç¢¼æ·»åŠ  OpenTelemetry instrumentation
# (ç¯„ä¾‹: KPIMON)

# requirements.txt æ·»åŠ :
# opentelemetry-api
# opentelemetry-sdk
# opentelemetry-instrumentation-flask
# opentelemetry-exporter-jaeger

# kpimon.py æ·»åŠ :
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.jaeger.thrift import JaegerExporter

tracer_provider = TracerProvider()
jaeger_exporter = JaegerExporter(
    agent_host_name="jaeger-agent.observability.svc",
    agent_port=6831,
)
tracer_provider.add_span_processor(BatchSpanProcessor(jaeger_exporter))
trace.set_tracer_provider(tracer_provider)
tracer = trace.get_tracer(__name__)

# åœ¨é—œéµå‡½æ•¸æ·»åŠ  span
@tracer.start_as_current_span("process_kpi_indication")
def process_kpi_indication(indication):
    # ...

# Step 4: é‡å»ºä¸¦éƒ¨ç½²æ‰€æœ‰ xApps
```

#### é©—æ”¶æ¨™æº–
- [ ] Jaeger UI å¯è¨ªå•
- [ ] å¯çœ‹åˆ° xApps çš„ traces
- [ ] å¯è¿½è¹¤å®Œæ•´è«‹æ±‚éˆè·¯ï¼ˆE2 Sim â†’ KPIMON â†’ Redis â†’ InfluxDBï¼‰
- [ ] P99 å»¶é² < 50ms

---

### ä»»å‹™ 22: E2 Indication Batching å„ªåŒ–

**è² è²¬äºº**: Performance Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P2

#### åŸ·è¡Œæ­¥é©Ÿ

```python
# Step 1: ä¿®æ”¹ E2 Simulator æ”¯æ´ batching
# simulator/e2-simulator/src/e2_simulator.py

class E2Simulator:
    def __init__(self):
        self.batch_size = int(os.getenv('BATCH_SIZE', '10'))
        self.batch_interval = int(os.getenv('BATCH_INTERVAL', '1'))  # ç§’
        self.indication_buffer = []

    def generate_batched_indications(self) -> List[Dict]:
        """ç”Ÿæˆæ‰¹æ¬¡ indications"""
        indications = []
        for _ in range(self.batch_size):
            indications.append(self.generate_kpi_indication())
        return indications

    def send_batched_indications(self, xapp_name: str):
        """æ‰¹æ¬¡ç™¼é€ indications"""
        batch = self.generate_batched_indications()

        url = f"http://{self.config['xapps'][xapp_name]['host']}:" \
              f"{self.config['xapps'][xapp_name]['port']}" \
              f"{self.config['xapps'][xapp_name]['endpoint']}/batch"

        try:
            response = requests.post(url, json=batch, timeout=5)
            if response.status_code == 200:
                self.BATCHES_SENT.labels(xapp=xapp_name).inc()
                logger.info(f"Sent batch of {len(batch)} indications to {xapp_name}")
        except Exception as e:
            logger.error(f"Failed to send batch to {xapp_name}: {e}")

# Step 2: ä¿®æ”¹ KPIMON æ”¯æ´ batch processing
# xapps/kpimon/src/kpimon.py

@app.route('/e2/indication/batch', methods=['POST'])
def handle_batch_indication():
    """è™•ç†æ‰¹æ¬¡ E2 indications"""
    indications = request.json

    with tracer.start_as_current_span("process_batch") as span:
        span.set_attribute("batch_size", len(indications))

        # ä¸¦è¡Œè™•ç† indications
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(process_single_indication, ind)
                      for ind in indications]
            results = [f.result() for f in futures]

        # æ‰¹æ¬¡å¯«å…¥ Redis
        pipe = sdl.redis_client.pipeline()
        for ind in indications:
            pipe.set(f"kpi:{ind['cell_id']}:{ind['timestamp']}",
                    json.dumps(ind))
        pipe.execute()

        # æ‰¹æ¬¡å¯«å…¥ InfluxDB
        points = [
            Point("kpi")
            .tag("cell_id", ind["cell_id"])
            .field("prb_usage", ind["kpi_value"])
            .time(ind["timestamp"])
            for ind in indications
        ]
        influx_write_api.write(bucket="ricplt", record=points)

    return jsonify({"status": "success", "processed": len(indications)})

# Step 3: æ•ˆèƒ½æ¸¬è©¦
# æ¸¬è©¦ä¸åŒ batch size çš„ååé‡èˆ‡å»¶é²
```

#### é©—æ”¶æ¨™æº–
- [ ] Batch size = 10 æ™‚ååé‡æå‡ 5x
- [ ] P99 å»¶é² < 20ms
- [ ] CPU ä½¿ç”¨ç‡é™ä½ 30%
- [ ] Redis/InfluxDB å¯«å…¥æ¬¡æ•¸æ¸›å°‘ 10x

---

### Sprint 4 Review

**æ™‚é–“**: 2026-01-15 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] è³‡æºé…ç½®å„ªåŒ–å®Œæˆ
- [ ] HPA é‹è¡Œæ­£å¸¸
- [ ] Jaeger tracing å¯è¦–åŒ–å®Œæ•´è«‹æ±‚éˆè·¯
- [ ] E2 batching ååé‡æå‡ 5x

**é‡Œç¨‹ç¢‘**:
ğŸ‰ **Phase 2 å®Œæˆï¼ç³»çµ±å¯æ”¯æ´ 50+ E2 nodes**

---

## Phase 3: æ¸¬è©¦èˆ‡ CI/CD (Week 9-12)

### Sprint 5: æ¸¬è©¦åŸºç¤è¨­æ–½ (Week 9-10)

#### ğŸ“… æ™‚ç¨‹ï¼š2026-01-16 ~ 2026-01-29 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å»ºç«‹ pytest æ¸¬è©¦æ¡†æ¶
- Mock SDL/RMR/Prometheus å®¢æˆ¶ç«¯
- KPIMON + Traffic Steering å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%

---

### ä»»å‹™ 23: å»ºç«‹ pytest æ¡†æ¶

**è² è²¬äºº**: QA Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: å®‰è£æ¸¬è©¦ä¾è³´
cd /home/thc1006/oran-ric-platform/xapps/kpimon

cat > requirements-dev.txt <<EOF
pytest==7.4.3
pytest-cov==4.1.0
pytest-mock==3.12.0
pytest-asyncio==0.21.1
pytest-xdist==3.5.0  # ä¸¦è¡Œæ¸¬è©¦
pytest-benchmark==4.0.0
fakeredis==2.20.0
EOF

pip install -r requirements-dev.txt

# Step 2: å‰µå»ºæ¸¬è©¦ç›®éŒ„çµæ§‹
mkdir -p tests/{unit,integration,fixtures}
touch tests/__init__.py
touch tests/conftest.py

# Step 3: å‰µå»º conftest.py (å…±ç”¨ fixtures)
cat > tests/conftest.py <<EOF
import pytest
from unittest.mock import MagicMock
from fakeredis import FakeRedis

@pytest.fixture
def mock_sdl():
    """Mock SDL client"""
    mock = MagicMock()
    mock.redis_client = FakeRedis()
    return mock

@pytest.fixture
def mock_rmr():
    """Mock RMR client"""
    mock = MagicMock()
    mock.send_message = MagicMock(return_value=True)
    return mock

@pytest.fixture
def mock_metrics():
    """Mock Prometheus metrics"""
    mock = MagicMock()
    return mock

@pytest.fixture
def sample_kpi_indication():
    """Sample KPI indication"""
    return {
        "cell_id": "cell_001",
        "ue_id": "ue_001",
        "kpi_type": "RRU.PrbUsedDl",
        "kpi_value": 45.5,
        "timestamp": "2025-01-16T10:00:00Z"
    }
EOF

# Step 4: å‰µå»º pytest.ini
cat > pytest.ini <<EOF
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    -v
    --cov=src
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=60
    -n auto  # ä¸¦è¡Œæ¸¬è©¦
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Slow tests
EOF
```

#### é©—æ”¶æ¨™æº–
- [ ] pytest æ¡†æ¶é…ç½®å®Œæˆ
- [ ] åŸ·è¡Œ `pytest` æˆåŠŸ
- [ ] Coverage å ±å‘Šç”Ÿæˆ
- [ ] ä¸¦è¡Œæ¸¬è©¦é‹è¡ŒæˆåŠŸ

---

### ä»»å‹™ 24: Mock æ¡†æ¶é–‹ç™¼

**è² è²¬äºº**: Developer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```python
# Step 1: å‰µå»º MockSDL
# tests/fixtures/mock_sdl.py

class MockSDL:
    """Mock Shared Data Layer"""

    def __init__(self):
        self.data = {}
        self.call_count = {}

    def set(self, key: str, value: str) -> bool:
        self.data[key] = value
        self._increment_call('set')
        return True

    def get(self, key: str) -> Optional[str]:
        self._increment_call('get')
        return self.data.get(key)

    def delete(self, key: str) -> bool:
        if key in self.data:
            del self.data[key]
            self._increment_call('delete')
            return True
        return False

    def _increment_call(self, method: str):
        self.call_count[method] = self.call_count.get(method, 0) + 1

    def reset(self):
        self.data.clear()
        self.call_count.clear()

# Step 2: å‰µå»º MockRMR
# tests/fixtures/mock_rmr.py

class MockRMR:
    """Mock RIC Message Router"""

    def __init__(self):
        self.sent_messages = []
        self.received_messages = []

    def send(self, msg_type: int, payload: bytes,
             meid: str = None) -> bool:
        self.sent_messages.append({
            'type': msg_type,
            'payload': payload,
            'meid': meid,
            'timestamp': time.time()
        })
        return True

    def receive(self, timeout: int = 1000) -> Optional[Dict]:
        if self.received_messages:
            return self.received_messages.pop(0)
        return None

    def inject_message(self, msg_type: int, payload: bytes):
        """æ¸¬è©¦ç”¨ï¼šæ³¨å…¥æ¥æ”¶è¨Šæ¯"""
        self.received_messages.append({
            'type': msg_type,
            'payload': payload
        })

# Step 3: å‰µå»º MockMetrics
# tests/fixtures/mock_metrics.py

class MockMetricsCollector:
    """Mock Prometheus Metrics Collector"""

    def __init__(self):
        self.counters = {}
        self.gauges = {}
        self.histograms = {}

    def counter(self, name: str) -> MockCounter:
        if name not in self.counters:
            self.counters[name] = MockCounter(name)
        return self.counters[name]

    def gauge(self, name: str) -> MockGauge:
        if name not in self.gauges:
            self.gauges[name] = MockGauge(name)
        return self.gauges[name]

    def histogram(self, name: str) -> MockHistogram:
        if name not in self.histograms:
            self.histograms[name] = MockHistogram(name)
        return self.histograms[name]

class MockCounter:
    def __init__(self, name: str):
        self.name = name
        self.value = 0
        self.labels_dict = {}

    def labels(self, **kwargs):
        key = tuple(sorted(kwargs.items()))
        if key not in self.labels_dict:
            self.labels_dict[key] = MockCounter(f"{self.name}_{key}")
        return self.labels_dict[key]

    def inc(self, amount: int = 1):
        self.value += amount
```

#### é©—æ”¶æ¨™æº–
- [ ] MockSDL é€šéæ‰€æœ‰ SDL æ¸¬è©¦
- [ ] MockRMR é€šéæ‰€æœ‰ RMR æ¸¬è©¦
- [ ] MockMetrics è¨˜éŒ„æ‰€æœ‰ metrics æ“ä½œ
- [ ] Mock ç‰©ä»¶å¯å®Œå…¨æ›¿ä»£çœŸå¯¦ç‰©ä»¶

---

### ä»»å‹™ 25: KPIMON å–®å…ƒæ¸¬è©¦

**è² è²¬äºº**: Developer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```python
# tests/unit/test_kpimon_processor.py

import pytest
from src.kpimon import KPIProcessor

class TestKPIProcessor:

    @pytest.fixture
    def processor(self, mock_sdl, mock_rmr, mock_metrics):
        return KPIProcessor(
            sdl=mock_sdl,
            rmr=mock_rmr,
            metrics=mock_metrics
        )

    def test_process_valid_indication(self, processor, sample_kpi_indication):
        """æ¸¬è©¦è™•ç†æœ‰æ•ˆçš„ KPI indication"""
        result = processor.process_indication(sample_kpi_indication)

        assert result is True
        assert processor.sdl.get(f"kpi:{sample_kpi_indication['cell_id']}") is not None
        assert processor.metrics.counters['kpimon_messages_received_total'].value == 1

    def test_process_invalid_indication(self, processor):
        """æ¸¬è©¦è™•ç†ç„¡æ•ˆçš„ indication"""
        invalid_indication = {"invalid": "data"}

        result = processor.process_indication(invalid_indication)

        assert result is False
        assert processor.metrics.counters['kpimon_errors_total'].value == 1

    def test_high_prb_usage_alert(self, processor):
        """æ¸¬è©¦ PRB ä½¿ç”¨ç‡éé«˜å‘Šè­¦"""
        high_prb_indication = {
            "cell_id": "cell_001",
            "kpi_type": "RRU.PrbUsedDl",
            "kpi_value": 95.0  # è¶…éé–¾å€¼ 85%
        }

        processor.process_indication(high_prb_indication)

        # é©—è­‰å‘Šè­¦è¨Šæ¯å·²ç™¼é€
        sent_messages = processor.rmr.sent_messages
        assert len(sent_messages) == 1
        assert sent_messages[0]['type'] == 12050  # RIC_INDICATION

    @pytest.mark.parametrize("kpi_value,expected_alarm", [
        (50.0, False),
        (85.0, False),
        (85.1, True),
        (100.0, True),
    ])
    def test_prb_threshold(self, processor, kpi_value, expected_alarm):
        """æ¸¬è©¦ä¸åŒ PRB å€¼çš„å‘Šè­¦è¡Œç‚º"""
        indication = {
            "cell_id": "cell_001",
            "kpi_type": "RRU.PrbUsedDl",
            "kpi_value": kpi_value
        }

        processor.process_indication(indication)

        if expected_alarm:
            assert len(processor.rmr.sent_messages) > 0
        else:
            assert len(processor.rmr.sent_messages) == 0

# tests/unit/test_kpimon_subscription.py

class TestSubscriptionManager:

    def test_create_subscription(self, processor):
        """æ¸¬è©¦å‰µå»ºè¨‚é–±"""
        sub_req = {
            "subscription_id": "sub_001",
            "cell_id": "cell_001",
            "kpi_types": ["RRU.PrbUsedDl", "RRU.PrbUsedUl"]
        }

        result = processor.create_subscription(sub_req)

        assert result is True
        assert processor.sdl.get("subscription:sub_001") is not None

    def test_duplicate_subscription(self, processor):
        """æ¸¬è©¦é‡è¤‡è¨‚é–±"""
        sub_req = {"subscription_id": "sub_001"}

        processor.create_subscription(sub_req)
        result = processor.create_subscription(sub_req)

        assert result is False
        assert processor.metrics.counters['kpimon_subscription_failures_total'].value == 1

# åŸ·è¡Œæ¸¬è©¦
# pytest tests/unit/ -v --cov=src --cov-report=html
```

#### é©—æ”¶æ¨™æº–
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+
- [ ] æ‰€æœ‰æ¸¬è©¦é€šé
- [ ] æ¸¬è©¦åŸ·è¡Œæ™‚é–“ < 10 ç§’
- [ ] Coverage å ±å‘Šç”Ÿæˆæ–¼ `htmlcov/`

---

### ä»»å‹™ 26: Traffic Steering å–®å…ƒæ¸¬è©¦

**è² è²¬äºº**: Developer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```python
# tests/unit/test_ts_algorithm.py

import pytest
from src.traffic_steering import LoadBalancingAlgorithm

class TestLoadBalancingAlgorithm:

    @pytest.fixture
    def algorithm(self):
        return LoadBalancingAlgorithm()

    def test_select_target_cell_round_robin(self, algorithm):
        """æ¸¬è©¦ Round Robin è² è¼‰å‡è¡¡"""
        cells = ["cell_001", "cell_002", "cell_003"]

        # é€£çºŒ 6 æ¬¡è«‹æ±‚æ‡‰ä¾åºé¸æ“‡ cell
        results = [algorithm.select_target_cell(cells) for _ in range(6)]

        assert results == ["cell_001", "cell_002", "cell_003",
                          "cell_001", "cell_002", "cell_003"]

    def test_select_target_cell_load_based(self, algorithm, mock_sdl):
        """æ¸¬è©¦åŸºæ–¼è² è¼‰çš„é¸æ“‡"""
        # æ¨¡æ“¬ä¸åŒ cell çš„è² è¼‰
        mock_sdl.set("load:cell_001", "90")  # é«˜è² è¼‰
        mock_sdl.set("load:cell_002", "50")  # ä¸­è² è¼‰
        mock_sdl.set("load:cell_003", "30")  # ä½è² è¼‰

        cells = ["cell_001", "cell_002", "cell_003"]

        # æ‡‰é¸æ“‡è² è¼‰æœ€ä½çš„ cell_003
        result = algorithm.select_target_cell(cells, strategy="load_based")

        assert result == "cell_003"

    @pytest.mark.benchmark
    def test_algorithm_performance(self, algorithm, benchmark):
        """æ•ˆèƒ½æ¸¬è©¦ï¼š1000 æ¬¡æ±ºç­–æ‡‰ < 100ms"""
        cells = ["cell_001", "cell_002", "cell_003"]

        def run_decisions():
            for _ in range(1000):
                algorithm.select_target_cell(cells)

        result = benchmark(run_decisions)

        assert result.stats.mean < 0.0001  # < 0.1ms per decision

# tests/unit/test_ts_handover.py

class TestHandoverManager:

    def test_initiate_handover(self, manager, mock_rmr):
        """æ¸¬è©¦ç™¼èµ·åˆ‡æ›"""
        handover_req = {
            "ue_id": "ue_001",
            "source_cell": "cell_001",
            "target_cell": "cell_002"
        }

        result = manager.initiate_handover(handover_req)

        assert result is True
        # é©—è­‰ RMR è¨Šæ¯å·²ç™¼é€
        assert len(mock_rmr.sent_messages) == 1
        assert mock_rmr.sent_messages[0]['type'] == 12030  # RIC_CONTROL_REQ

    def test_handover_failure_handling(self, manager):
        """æ¸¬è©¦åˆ‡æ›å¤±æ•—è™•ç†"""
        handover_req = {
            "ue_id": "ue_001",
            "source_cell": "cell_001",
            "target_cell": "nonexistent_cell"  # ä¸å­˜åœ¨çš„ cell
        }

        result = manager.initiate_handover(handover_req)

        assert result is False
        assert manager.metrics.counters['ts_handover_failures_total'].value == 1

# åŸ·è¡Œæ¸¬è©¦
# pytest tests/unit/ --benchmark-only
```

#### é©—æ”¶æ¨™æº–
- [ ] å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+
- [ ] æ‰€æœ‰æ¸¬è©¦é€šé
- [ ] æ•ˆèƒ½æ¸¬è©¦é”æ¨™ï¼ˆ1000 decisions < 100msï¼‰
- [ ] é‚Šç•Œæ¢ä»¶æ¸¬è©¦å®Œæ•´

---

### Sprint 5 Review

**æ™‚é–“**: 2026-01-29 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] pytest æ¡†æ¶å»ºç«‹å®Œæˆ
- [ ] Mock æ¡†æ¶å¯å®Œå…¨æ›¿ä»£çœŸå¯¦çµ„ä»¶
- [ ] KPIMON å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+
- [ ] Traffic Steering å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+

---

### Sprint 6: CI/CD Pipeline (Week 11-12)

#### ğŸ“… æ™‚ç¨‹ï¼š2026-01-30 ~ 2026-02-12 (2 é€±)

#### ğŸ¯ Sprint ç›®æ¨™
- å»ºç«‹ GitHub Actions CI/CD workflow
- æ•´åˆæ¸¬è©¦ã€lintingã€å®‰å…¨æƒæ
- Helm chart è‡ªå‹•åŒ–æ¸¬è©¦
- E2E æ¸¬è©¦è‡ªå‹•åŒ–

---

### ä»»å‹™ 27: å»ºç«‹ GitHub Actions CI

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```yaml
# .github/workflows/ci.yml

name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        pip install flake8 black pylint

    - name: Run flake8
      run: flake8 xapps/ --max-line-length=120

    - name: Run black
      run: black --check xapps/

    - name: Run pylint
      run: pylint xapps/ --fail-under=8.0

  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        xapp: [kpimon, traffic-steering, qoe-predictor, ran-control]
    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        cd xapps/${{ matrix.xapp }}
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run tests
      run: |
        cd xapps/${{ matrix.xapp }}
        pytest tests/ -v --cov=src --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./xapps/${{ matrix.xapp }}/coverage.xml
        flags: ${{ matrix.xapp }}

  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH'

    - name: Upload Trivy results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  build:
    needs: [lint, test, security]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        xapp: [kpimon, traffic-steering, qoe-predictor, ran-control, federated-learning]
    steps:
    - uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Build xApp image
      uses: docker/build-push-action@v4
      with:
        context: xapps/${{ matrix.xapp }}
        push: false
        tags: localhost:5000/xapp-${{ matrix.xapp }}:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

git add .github/workflows/ci.yml
git commit -m "ci: Add comprehensive CI pipeline"
git push
```

#### é©—æ”¶æ¨™æº–
- [ ] CI pipeline åœ¨æ¯æ¬¡ push æ™‚è‡ªå‹•åŸ·è¡Œ
- [ ] æ‰€æœ‰ jobs æˆåŠŸé€šé
- [ ] Coverage å ±å‘Šä¸Šå‚³åˆ° Codecov
- [ ] å®‰å…¨æƒæçµæœé¡¯ç¤ºåœ¨ Security tab

---

### ä»»å‹™ 28: Helm Chart è‡ªå‹•åŒ–æ¸¬è©¦

**è² è²¬äºº**: DevOps Engineer
**å·¥æ™‚**: 8 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```bash
# Step 1: ç‚ºæ¯å€‹ Helm chart å‰µå»ºæ¸¬è©¦
# xapps/kpimon/chart/templates/tests/test-connection.yaml

apiVersion: v1
kind: Pod
metadata:
  name: "{{ include "kpimon.fullname" . }}-test-connection"
  labels:
    {{- include "kpimon.labels" . | nindent 4 }}
  annotations:
    "helm.sh/hook": test
spec:
  containers:
  - name: wget
    image: busybox
    command: ['wget']
    args: ['{{ include "kpimon.fullname" . }}:8080/ric/v1/health/ready']
  restartPolicy: Never

# Step 2: æ·»åŠ  Helm lint åˆ° CI
# .github/workflows/helm-test.yml

name: Helm Tests

on: [push, pull_request]

jobs:
  helm-lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Install Helm
      uses: azure/setup-helm@v3
      with:
        version: '3.13.0'

    - name: Lint Helm charts
      run: |
        for chart in xapps/*/chart; do
          echo "Linting $chart"
          helm lint $chart
        done

  helm-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Create k3s cluster
      uses: debianmaster/actions-k3s@master
      with:
        version: 'v1.28.5-k3s1'

    - name: Install Helm charts
      run: |
        for chart in xapps/kpimon/chart xapps/traffic-steering/chart; do
          helm install $(basename $(dirname $chart)) $chart \
            --wait --timeout 5m
        done

    - name: Run Helm tests
      run: |
        helm test kpimon
        helm test traffic-steering

# Step 3: Chart version bump automation
# scripts/bump-chart-version.sh

#!/bin/bash
set -e

CHART_PATH=$1
VERSION_TYPE=$2  # major, minor, patch

current_version=$(grep '^version:' $CHART_PATH/Chart.yaml | awk '{print $2}')

IFS='.' read -ra ADDR <<< "$current_version"
major=${ADDR[0]}
minor=${ADDR[1]}
patch=${ADDR[2]}

case $VERSION_TYPE in
  major) ((major++)); minor=0; patch=0 ;;
  minor) ((minor++)); patch=0 ;;
  patch) ((patch++)) ;;
esac

new_version="$major.$minor.$patch"

sed -i "s/^version: .*/version: $new_version/" $CHART_PATH/Chart.yaml
echo "Bumped version from $current_version to $new_version"
```

#### é©—æ”¶æ¨™æº–
- [ ] æ‰€æœ‰ Helm charts é€šé lint
- [ ] Helm test hooks è‡ªå‹•åŸ·è¡Œ
- [ ] Chart version bump è…³æœ¬å¯ç”¨
- [ ] CI è‡ªå‹•æ¸¬è©¦ chart éƒ¨ç½²

---

### ä»»å‹™ 29: E2E æ¸¬è©¦è‡ªå‹•åŒ–

**è² è²¬äºº**: QA Engineer
**å·¥æ™‚**: 12 å°æ™‚
**å„ªå…ˆç´š**: P3

#### åŸ·è¡Œæ­¥é©Ÿ

```python
# tests/e2e/test_complete_flow.py

import pytest
import requests
import time
from kubernetes import client, config

class TestCompleteE2EFlow:

    @pytest.fixture(scope="class")
    def k8s_client(self):
        """Kubernetes client"""
        config.load_kube_config()
        return client.CoreV1Api()

    def test_01_all_pods_running(self, k8s_client):
        """æ¸¬è©¦ 1: æ‰€æœ‰ Pods é‹è¡Œä¸­"""
        # Check ricplt namespace
        ricplt_pods = k8s_client.list_namespaced_pod(namespace="ricplt")
        for pod in ricplt_pods.items:
            assert pod.status.phase == "Running", \
                f"Pod {pod.metadata.name} not running: {pod.status.phase}"

        # Check ricxapp namespace
        ricxapp_pods = k8s_client.list_namespaced_pod(namespace="ricxapp")
        for pod in ricxapp_pods.items:
            assert pod.status.phase == "Running", \
                f"Pod {pod.metadata.name} not running: {pod.status.phase}"

    def test_02_e2_simulator_sends_indications(self, k8s_client):
        """æ¸¬è©¦ 2: E2 Simulator ç™¼é€ indications"""
        # å–å¾— E2 Simulator logs
        logs = k8s_client.read_namespaced_pod_log(
            name="e2-simulator-xxxxx",
            namespace="ricxapp",
            tail_lines=100
        )

        # é©—è­‰å‘æ‰€æœ‰ xApps ç™¼é€
        assert "Sent indication to kpimon" in logs
        assert "Sent indication to traffic-steering" in logs
        assert "Sent indication to qoe-predictor" in logs
        assert "Sent indication to ran-control" in logs
        assert "Sent indication to federated-learning" in logs

    def test_03_kpimon_processes_indications(self):
        """æ¸¬è©¦ 3: KPIMON è™•ç† indications"""
        # æŸ¥è©¢ Prometheus metrics
        response = requests.get(
            "http://prometheus-server.ricplt.svc:80/api/v1/query",
            params={"query": "kpimon_messages_received_total"}
        )

        assert response.status_code == 200
        data = response.json()['data']['result']
        assert len(data) > 0

        # é©—è­‰ counter æœ‰å¢åŠ 
        value = float(data[0]['value'][1])
        assert value > 0

    def test_04_data_written_to_redis(self, k8s_client):
        """æ¸¬è©¦ 4: è³‡æ–™å¯«å…¥ Redis"""
        # é€²å…¥ Redis Pod åŸ·è¡ŒæŸ¥è©¢
        exec_command = [
            '/bin/sh',
            '-c',
            'redis-cli -a $REDIS_PASSWORD KEYS "kpi:*" | wc -l'
        ]

        resp = stream(
            k8s_client.connect_get_namespaced_pod_exec,
            "redis-ha-master-0",
            "ricplt",
            command=exec_command,
            stderr=True, stdin=False,
            stdout=True, tty=False
        )

        key_count = int(resp.strip())
        assert key_count > 0, "No KPI data in Redis"

    def test_05_data_written_to_influxdb(self):
        """æ¸¬è©¦ 5: è³‡æ–™å¯«å…¥ InfluxDB"""
        response = requests.post(
            "http://influxdb.ricplt.svc:8086/api/v2/query",
            headers={
                "Authorization": f"Token {INFLUXDB_TOKEN}",
                "Content-Type": "application/json"
            },
            json={
                "query": """
                    from(bucket: "ricplt")
                      |> range(start: -5m)
                      |> filter(fn: (r) => r["_measurement"] == "kpi")
                      |> count()
                """,
                "type": "flux"
            }
        )

        assert response.status_code == 200
        # é©—è­‰æœ‰è³‡æ–™é»
        # ...

    def test_06_grafana_dashboards_accessible(self):
        """æ¸¬è©¦ 6: Grafana dashboard å¯è¨ªå•"""
        response = requests.get(
            "http://oran-grafana.ricplt.svc/api/dashboards/uid/oran-ric-overview",
            auth=("admin", GRAFANA_PASSWORD)
        )

        assert response.status_code == 200

    def test_07_alertmanager_receives_alerts(self):
        """æ¸¬è©¦ 7: AlertManager æ¥æ”¶å‘Šè­¦"""
        response = requests.get(
            "http://alertmanager.ricplt.svc:9093/api/v2/alerts"
        )

        assert response.status_code == 200
        # é©—è­‰å‘Šè­¦è¦å‰‡å·²è¼‰å…¥
        # ...

# åŸ·è¡Œ E2E æ¸¬è©¦
# pytest tests/e2e/ -v --maxfail=1
```

#### é©—æ”¶æ¨™æº–
- [ ] 7 å€‹ E2E æ¸¬è©¦å…¨éƒ¨é€šé
- [ ] æ¸¬è©¦åŸ·è¡Œæ™‚é–“ < 5 åˆ†é˜
- [ ] CI è‡ªå‹•åŸ·è¡Œ E2E æ¸¬è©¦
- [ ] æ¸¬è©¦å¤±æ•—æ™‚æä¾›è©³ç´°æ—¥èªŒ

---

### Sprint 6 Review & Retrospective

**æ™‚é–“**: 2026-02-12 (é€±ä¸‰) 14:00-16:00

**æª¢è¦–é …ç›®**:
- [ ] GitHub Actions CI/CD pipeline å®Œæ•´
- [ ] æ‰€æœ‰ jobs è‡ªå‹•åŸ·è¡Œ
- [ ] Helm charts é€šéè‡ªå‹•åŒ–æ¸¬è©¦
- [ ] E2E æ¸¬è©¦è¦†è“‹å®Œæ•´æµç¨‹

**é‡Œç¨‹ç¢‘**:
ğŸ‰ **Phase 3 å®Œæˆï¼å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 70%ï¼ŒCI/CD å®Œå…¨è‡ªå‹•åŒ–**

---

## ğŸ‰ 90 å¤©è¨ˆåŠƒå®Œæˆæ…¶ç¥

**æœ€çµ‚å›é¡§æœƒè­°**: 2026-02-16 (é€±æ—¥) 10:00-12:00

### æˆæœç¸½çµ

| æŒ‡æ¨™ | åˆå§‹å€¼ | ç›®æ¨™å€¼ | å¯¦éš›å€¼ | é”æˆç‡ |
|------|--------|--------|--------|--------|
| å¯ç”¨æ€§ | 99.9% | 99.99% | ? | ? |
| éƒ¨ç½²æˆåŠŸç‡ | 85% | 99% | ? | ? |
| å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ | 0% | 70% | ? | ? |
| å®‰å…¨æˆç†Ÿåº¦ | 5/10 | 8/10 | ? | ? |
| æŠ€è¡“å‚µå‹™è² æ“” | Medium | Low | ? | ? |

### ä¸‹ä¸€éšæ®µè¦åŠƒ

1. **æŒçºŒæ”¹é€²**
   - æ¯æœˆæŠ€è¡“å‚µå‹™å¯©æŸ¥
   - å­£åº¦å®‰å…¨ç¨½æ ¸
   - æ¯é€±æ•ˆèƒ½ç›£æ§

2. **æ–°åŠŸèƒ½é–‹ç™¼**
   - éµå¾ª TDD åŸå‰‡
   - æ‰€æœ‰æ–° PR éœ€é€šé CI/CD
   - Code coverage ä¸å¾—é™ä½

3. **çŸ¥è­˜åˆ†äº«**
   - å…§éƒ¨æŠ€è¡“åˆ†äº«æœƒ
   - æ–‡æª”æŒçºŒæ›´æ–°
   - æœ€ä½³å¯¦è¸ç¸½çµ

---

## é™„éŒ„ï¼šé©—æ”¶æ¨™æº–

### Phase 0 é©—æ”¶æ¨™æº–

- [ ] Redis AOF/RDB æŒä¹…åŒ–å•Ÿç”¨
- [ ] InfluxDB Retention Policy 90 å¤©
- [ ] ç„¡æ˜æ–‡å¯†ç¢¼å­˜åœ¨æ–¼ Git
- [ ] Redis éœ€å¯†ç¢¼èªè­‰
- [ ] E2 Simulator å‘ 5 å€‹ xApps ç™¼é€æµé‡
- [ ] æ¯æ—¥å‚™ä»½æˆåŠŸåŸ·è¡Œ

### Phase 1 é©—æ”¶æ¨™æº–

- [ ] æ‰€æœ‰å¯†ç¢¼å„²å­˜æ–¼ Sealed Secrets
- [ ] Git æ­·å²ç„¡æ•æ„Ÿè³‡è¨Š
- [ ] Trivy æƒææ•´åˆåˆ° CI/CD
- [ ] æ‰€æœ‰ xApps æœ‰ SecurityContext
- [ ] Pod Security Standards å¯¦æ–½
- [ ] Network Policy default-deny
- [ ] æ‰€æœ‰ xApps æœ‰å°ˆå±¬ ServiceAccount
- [ ] RBAC éµå¾ªæœ€å°æ¬Šé™
- [ ] Service Mesh mTLS å•Ÿç”¨

### Phase 2 é©—æ”¶æ¨™æº–

- [ ] Redis Sentinel HA é‹è¡Œ
- [ ] InfluxDB é›™å¯«æ©Ÿåˆ¶é‹è¡Œ
- [ ] PostgreSQL HA é‹è¡Œ
- [ ] RTO < 5 åˆ†é˜
- [ ] RPO < 1 åˆ†é˜
- [ ] è³‡æºé…ç½®å„ªåŒ–å®Œæˆ
- [ ] HPA è‡ªå‹•æ“´å±•æˆåŠŸ
- [ ] Jaeger è¿½è¹¤å®Œæ•´éˆè·¯
- [ ] E2 batching ååé‡æå‡ 5x

### Phase 3 é©—æ”¶æ¨™æº–

- [ ] pytest æ¡†æ¶å»ºç«‹
- [ ] Mock æ¡†æ¶å®Œæ•´
- [ ] KPIMON å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+
- [ ] Traffic Steering å–®å…ƒæ¸¬è©¦è¦†è“‹ç‡ 60%+
- [ ] GitHub Actions CI é‹è¡Œæ­£å¸¸
- [ ] Helm charts é€šéè‡ªå‹•åŒ–æ¸¬è©¦
- [ ] E2E æ¸¬è©¦å®Œæ•´

---

**ä½œè€…**: è”¡ç§€å‰ (thc1006)
**å‰µå»ºæ—¥æœŸ**: 2025-11-17
**æœ€å¾Œæ›´æ–°**: 2025-11-17
**è¿½è¹¤**: æ¯é€±ä¸€æ›´æ–°é€²åº¦
