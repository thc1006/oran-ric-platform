apiVersion: apps/v1
kind: Deployment
metadata:
  name: federated-learning-gpu
  namespace: ricxapp
  labels:
    app: federated-learning
    xapp: federated-learning
    version: v1.0.0-gpu
spec:
  replicas: 1
  selector:
    matchLabels:
      app: federated-learning
      version: v1.0.0-gpu
  template:
    metadata:
      labels:
        app: federated-learning
        xapp: federated-learning
        version: v1.0.0-gpu
    spec:
      serviceAccountName: federated-learning-sa
      # Node selector for GPU nodes
      nodeSelector:
        nvidia.com/gpu: "true"
      # Tolerations for GPU nodes (if tainted)
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      containers:
      - name: federated-learning
        image: localhost:5000/xapp-federated-learning:1.0.0-gpu
        imagePullPolicy: IfNotPresent
        ports:
        - name: rmr-data
          containerPort: 4590
          protocol: TCP
        - name: rmr-route
          containerPort: 4591
          protocol: TCP
        - name: http-api
          containerPort: 8110
          protocol: TCP
        env:
        - name: RMR_SRC_ID
          value: "federated-learning"
        - name: RMR_SEED_RT
          value: "/app/config/rmr-routes.txt"
        - name: REDIS_HOST
          value: "redis-service.ricplt"
        - name: REDIS_PORT
          value: "6379"
        - name: REDIS_DB
          value: "3"
        - name: PYTHONUNBUFFERED
          value: "1"
        - name: FL_MODE
          value: "production"
        - name: FL_GPU_ENABLED
          value: "true"
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: NVIDIA_VISIBLE_DEVICES
          value: "all"
        - name: NVIDIA_DRIVER_CAPABILITIES
          value: "compute,utility"
        resources:
          requests:
            cpu: "2000m"
            memory: "4Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "8000m"
            memory: "12Gi"
            nvidia.com/gpu: "1"
        livenessProbe:
          httpGet:
            path: /health/alive
            port: 8110
          initialDelaySeconds: 90
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 8110
          initialDelaySeconds: 90
          periodSeconds: 20
          timeoutSeconds: 10
          successThreshold: 1
          failureThreshold: 3
        volumeMounts:
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: models
          mountPath: /app/models
        - name: data
          mountPath: /app/data
        # Optional: Mount SHM for larger shared memory (useful for PyTorch DataLoader)
        - name: dshm
          mountPath: /dev/shm
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
          fsGroup: 1000
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: false
      volumes:
      - name: config
        configMap:
          name: federated-learning-config
      - name: models
        persistentVolumeClaim:
          claimName: federated-learning-models-pvc
      - name: data
        emptyDir: {}
      # Shared memory for PyTorch (default 64MB may be too small)
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 2Gi
      restartPolicy: Always
      dnsPolicy: ClusterFirst
